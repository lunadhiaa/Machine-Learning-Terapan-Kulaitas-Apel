# -*- coding: utf-8 -*-
"""Quality-Apples.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HX3DLnOv-CVov2RaAyk-xMu-bKc2TMjn

## **Proyek Machine Learning - Lulu Nadhiatun Anisa** ##

---

![Image Apel](https://www.astronauts.id/blog/wp-content/uploads/2022/12/Kenali-Jenis-jenis-Buah-Apel-dan-Manfaatnya-1024x683.jpg)

## **Deskripsi Proyek**

### **Deskripsi Latar Belakang Prediksi Kualitas Apel dengan Machine Learning**


Proyek ini bertujuan untuk mengembangkan model machine learning yang dapat memprediksi kualitas apel dengan lebih akurat dan efisien. Saat ini, penentuan kualitas apel masih dilakukan secara manual, yang memakan waktu, tenaga, dan rentan terhadap kesalahan. Hal ini menyebabkan kerugian bagi petani dan distributor, serta memberikan produk yang tidak sesuai dengan harapan konsumen. Model prediksi kualitas apel dapat membantu mengatasi permasalahan ini dengan memberikan solusi yang lebih akurat, efisien, dan transparan.

# **Predictive Analytics: Kualitas Apel**
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/gdrive/MyDrive/Active/ML-TERAPAN'

"""## 1. Import Library"""

#Import Load data Library
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Import train test split
from sklearn.model_selection import train_test_split

# Import Minmaxscaler
from sklearn.preprocessing import MinMaxScaler

#Import Model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc

"""## 2. Data Understanding

Data Understanding merupakan proses memahami informasi dalam data dan menentukan kualitas dari data tersebut.

### 2.1 Data Loading



Data Loading merupakan tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.
Untuk informasi datasets ini telah di *bersihan* dan *normalisasi* terlebih dahulu oleh pembuat, sehingga mudah digunakan dan ramah bagi pemula.


<br>


**Informasi Datasets**


| Jenis | Keterangan |
| ------ | ------ |
| Title | Apple Quality |
| Source | [Kaggle](https://www.kaggle.com/datasets/nelgiriyewithana/apple-quality/data) |
| Maintainer | [Nidula Elgiriyewithana âš¡](https://www.kaggle.com/nelgiriyewithana) |
| License | Other (specified in description) |
| Visibility | Publik |
| Tags | Computer Science, Education, Food, Data Visualization, Classification, Exploratory Data Analysis |
| Usability | 10.00 |
"""

df = pd.read_csv('apple_quality.csv')
df

"""### 2.2 EDA *(Exploratory Data Analysis)*

Exploratory data analysis merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data. Teknik ini biasanya menggunakan bantuan statistik dan representasi grafis atau visualisasi.

#### EDA - Deskripsi Variabel Data
"""

df

"""Dari dataframe di atas kita dapat melihat bahwa pada dataset ini terdapat 9 kolom. Diantaranya:

- `A_id` : Pengidentifikasi unik untuk setiap buah
- `Size` : Ukuran buah
- `Weight` : Berat buah
- `Sweetness` : Tingkat kemanisan buah
- `Crunchiness` : Tekstur yang menunjukkan kerenyahan buah
-` Juiciness` : Tingkat kesegaran buah
- `Ripeness` : Tahap kematangan buah
- `Acidity` : Tingkat keasaman buah
- `Quality` : Kualitas buah secara keseluruhan
"""

df.drop("A_id",axis=1,inplace=True)

"""Dikarenakan kolom `A_id` tidak mempengaruhi model maka akan di drop / dihapus.




"""

df.info()

"""Dari eksekusi method `df.info()` terdapat:

- Terdapat 6 kolom numerik dengan tipe data float64 yaitu: Size, Weight, Sweetness, Crunchiness, Juiciness dan Ripeness.
- Terdapat 2 kolom dengan tipe data object yaitu: Acidity dan Quality.

Namun pada data aslinya kolom ` Acidity` adalah bertipe float64, yang nantinya akan kita rubah.
"""

df.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.
"""

df.shape

"""Dari eksekusi method` df.shape` Terlihat:
<br>

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 4001 | 8 |


<br>

#### EDA - Missing Value, Duplicates dan Outliers

**Missing Values Dan Duplicates Data**
"""

df.duplicated().sum()

"""Melihat apakah terdapat data yang terduplikat."""

df.Quality.value_counts(normalize=True)

df.isnull().sum()

data_missing = df[df.isnull().any(axis=1)]
data_missing

"""Dapat dilihat terdapat missing value yang mana akan kita hapus."""

df.dropna(inplace=True)
df.isnull().sum().sum()

df.describe()

def convert_acidity(acidity):
    try:
        return -float(acidity.replace('-', '')) if '-' in acidity else float(acidity)
    except ValueError:
        return np.nan


df['Acidity'] = df['Acidity'].apply(convert_acidity)

"""Merubah tipe data kolom `Acidity` menjadi data float64."""

df.info()

"""Dapat kita lihat:
- Jumlah data` Float64` ada 7 dan `object `ada 1.
"""

df.shape

"""**Visualisasi Outlier**"""

numerical_features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']
df_melted = df[numerical_features].melt(var_name='Feature', value_name='Value')

plt.figure(figsize=(20, 5))
sns.boxplot(x='Feature', y='Value', data=df_melted, palette='Purples')
plt.title('Box Plot of Features with Outliers', size=18)
plt.xlabel('Feature')
plt.ylabel('Value')
plt.show()

"""*Menghapus outliers yang ada pada dataset*  


Pada kasus ini, kita akan mendeteksi outliers dengan teknik visualisasi data (boxplot). Kemudian, menangani outliers dengan teknik IQR method.


```
IQR = Inter Quartile Range
IQR = Q3 - Q1
```


"""

numeric_df = df.select_dtypes(include=[float, int])
Q1 = numeric_df.quantile(0.25)
Q3 = numeric_df.quantile(0.75)
IQR = Q3 - Q1
df = df[~((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)]

df.shape

"""Jumlah Datasets setalah kita hapus Outlier: `3790, 8`

#### EDA - Univariate Analysis
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

plt.figure(figsize=(6,3))
colors = sns.light_palette("#7EACB5", n_colors=10)
sns.countplot(data=df, x='Quality', palette=[colors[4],colors[8]])
plt.xticks(ticks=[0,1], labels=['Bad', 'Good'])
plt.ylabel("Apple Count")
plt.title('Apply Quality Distribution')
plt.show()

"""#### EDA - Multivariate Analysis"""

sns.pairplot(df, diag_kind = 'kde')

colors = sns.light_palette("#7EACB5", n_colors=10)

plt.figure(figsize=(15, 10))
for i, column in enumerate(df.columns[:-1]):
    plt.subplot(3, 3, i + 1)
    sns.boxenplot(x='Quality', y=column, data=df, palette=[colors[4],colors[8]])
    plt.xticks(ticks=[0,1], labels=['Bad', 'Good'])
    plt.title(f'{column} by Quality')

plt.suptitle("Distribution of Apple Characteristics Across Good & Bad Quality", size=20)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Pilih hanya kolom numerik
df_numeric = df.select_dtypes(include=['number'])

# Menghitung matriks korelasi dan membulatkan ke dua desimal
correlation_matrix = df_numeric.corr().round(2)

# Plot heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)

# Menambahkan judul
plt.title("Matriks Korelasi untuk Fitur Numerik", size=20)
plt.show()

"""## 3. Data Preparation

#### Data Cleaning
"""

df.Quality = (df.Quality == "good").astype(int)  # good:1 , bad:0

x = df.drop("Quality",axis=1)
y = df.Quality

x.shape,y.shape

"""#### Train-Test-Split"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=60)

print(f'Total datasets: {len(x)}')
print(f'Total data Latih: {len(x_train)}')
print(f'Total data Uji: {len(x_test)}')

"""#### Normalisasi"""

scaler = MinMaxScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

"""## 3. Model Development

Model development adalah proses pembuatan dan pengembangan model

#### Support Vector Classifier (SVC)
"""

svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(x_train, y_train)

y_pred_svm = svm_model.predict(x_test)

"""#### Random Forest"""

rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(x_train, y_train)

y_pred_rf = rf.predict(x_test)

"""## 3. Evaluasi Model

#### Evaluasi Model Support Vector Classifier (SVC)
"""

print("Classification Report:\n", classification_report(y_test, y_pred_svm))
print("Accuracy Score:", round(accuracy_score(y_test, y_pred_svm) * 100),"%")

# Import library yang diperlukan
from sklearn.metrics import confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

# Mengaktifkan predict_proba di SVM
svm_model = SVC(kernel='linear', probability=True, random_state=42)
svm_model.fit(x_train, y_train)

# Prediksi label untuk data uji
y_pred_svm = svm_model.predict(x_test)

# Membuat confusion matrix
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)

# Menghasilkan probabilitas untuk ROC curve
y_probs_svm = svm_model.predict_proba(x_test)[:, 1]
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_probs_svm)
roc_auc_svm = auc(fpr_svm, tpr_svm)

# Membuat plot
fig, axs = plt.subplots(1, 2, figsize=(10, 4))

# Plot Confusion Matrix
sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Purples_r', cbar=False,
            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'], ax=axs[0])
axs[0].set_xlabel('Predicted Label')
axs[0].set_ylabel('True Label')
axs[0].set_title('Confusion Matrix')

# Plot ROC Curve
axs[1].plot(fpr_svm, tpr_svm, color='purple', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_svm)
axs[1].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
axs[1].set_xlim([0.0, 1.0])
axs[1].set_ylim([0.0, 1.05])
axs[1].set_xlabel('False Positive Rate')
axs[1].set_ylabel('True Positive Rate')
axs[1].set_title('Receiver Operating Characteristic (ROC)')
axs[1].legend(loc='lower right')

plt.suptitle("Model Evaluation - SVM", size=18)
plt.tight_layout()
plt.show()

"""#### Evaluasi Model Random Forest"""

# Evaluate the model
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Accuracy Score:", round(accuracy_score(y_test, y_pred_rf) * 100), "%")

# Model Evaluation
conf_matrix = confusion_matrix(y_test, y_pred_rf)

y_probs = rf.predict_proba(x_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

fig, axs = plt.subplots(1, 2, figsize=(10, 4))

# Plot Confusion Matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples_r', cbar=False,
            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'], ax=axs[0])
axs[0].set_xlabel('Predicted Label')
axs[0].set_ylabel('True Label')
axs[0].set_title('Confusion Matrix')

# Plot ROC Curve
axs[1].plot(fpr, tpr, color='purple', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
axs[1].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
axs[1].set_xlim([0.0, 1.0])
axs[1].set_ylim([0.0, 1.05])
axs[1].set_xlabel('False Positive Rate')
axs[1].set_ylabel('True Positive Rate')
axs[1].set_title('Receiver Operating Characteristic (ROC)')
axs[1].legend(loc='lower right')

plt.suptitle("Model Evaluation - Random Forest", size=18)
plt.tight_layout()
plt.show()

"""Model ini mencapai akurasi 89% dalam mengklasifikasikan kualitas apel. Kelas "Kualitas Buruk" dan "Kualitas Baik" memiliki performa seimbang, dengan presisi, perolehan, dan skor F1 masing-masing sebesar 89%. Hal ini menunjukkan bahwa model mampu membedakan kedua kategori kualitas dengan baik."""